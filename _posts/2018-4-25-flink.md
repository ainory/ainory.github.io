---
layout: post
title: Flink Stream Test
---

\[Flink\] Stream Test

*   Flink
    *   [https://flink.apache.org/introduction.html](https://flink.apache.org/introduction.html)
    *   flink server를 단독 또는 cluster로 구성하여 job을 등록하여 실행하는 구조
    *   event 처리에 특화 되어있다고함.
    *   savepoint를 활용하여 application의 version 정보를 관리함(rollback/upgrade)
    *   시간은 event / processing 둘다 사용가능함
    *   stateful stream processing
    *   여러가지 환경에 배포가 가능함
        *   local
            *   single JVM
            *   embedded
        *   cluster
            *   standalone
            *   yarn
            *   mesos
            *   docker
            *   kubernetes
            *   aws
            *   google compute engine
            *   mapR

    *   flink doc(v1.4)
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/](https://ci.apache.org/projects/flink/flink-docs-release-1.4/)
    *   Quickstart
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/setup_quickstart.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/setup_quickstart.html)

*   Dataflow Programing Model
    *   url
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/programming-model.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/programming-model.html)
    *   Level of Abstraction
                ![]({{ site.baseurl }}/images/2018-4-25-flink/20E7706D-4F55-411E-AEA1-E53518CA0AE2.svg)  
        *   Low-level building block
            *   단순히 추상적인 stateful streaming을 제공
            *   Process Function은 DataStream API에 포함됨
            *   사용자가 하나 이상의 stream에서 event를 자유롭게 처리하고, consistent fault tolerant state를 제공함
            *   사용자는 EventTime 또는 ProcessingTime callback을 등록가능하므로 프로그램에서 정교한 계산을 수행 가능

        *   Core APIs
            *   DataStream API(bounded/unbounded stream) DataSet API(bounded data set)
            *   user-specified transformations, joins, aggregations, windows, state 등 데이터 처리를 위한 공통 빌딩 블록을 제공함
            *   다양한 프로그래밍 언어로 지원됨
        
        *   Declarative DSL
            *   Table API는 동적으로 테이블을 변경할수 있는 테이블을 중심으로 하는 Declarative DSL
            *   Table API는 관계형 모델을 따름
            *   Table에는 Schema가 연결되어 있으며(RDBMS Table과 유사) select, project, join, group-by, aggregate 등과 같은 유사한 연산을 제공
            *   Operation Code가 어떻게 보이는지 정확하게 지정하기 보다는 논리적인 Operation을 선언으로 정의함
            *   다양한 유형의 사용자 정의 함수로 확장 가능하지만 Core API보다 표현력이 적지만 사용하기가 더 쉬움
            *   실행전에 최적화 규칙을 적용하는 옵티마이저를 통과함
            *   Table과 DataStream/DataSet을 완벽하게 변환하여 프로그램이 Table API와 Data Stream API를 혼합할수 있음
    
        *   SQL
            *   Flink가 제공하는 가장 높은 수준의 추상화
            *   Table API와 유사하지만 프로그램을 SQL 쿼리 표현식으로 나타냄
            *   SQL 추상화는 Table API와 상호 작용하며 SQL Query는 Table API에 정의된 테이블에 대해 실행가능

    *   Programs and DataFlows
                ![]({{ site.baseurl}}/images/2018-4-25-flink/5942B864-C649-4388-BBC9-08027E6FCFC0.png)  
        *   Source
            *   데이터를 입력받는 부분
            *   streaming connectors
                *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/index.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/index.html)
            *   batch connectors
                *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/connectors.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/connectors.html)

        *   Transformatior
            *   데이터를 변환하는 부분
            *   DataStream operators
                *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/index.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/index.html)
            *   DataSet transformations
                *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/dataset_transformations.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/dataset_transformations.html)
    
        *   Sink
            *   변환된 데이터를 다른곳으로 보내는 부분
    
    *   Parallel DataFlows
                ![]({{ site.baseurl}}/images/2018-4-25-flink/87217348-B48A-47DD-8D03-F85D7A917644.png)  
        *   Flink Program은 본질적으로 Parallel and Distributed
        *   실행 중에 stream은 하나 또는 그 이상의 stream partition을 가지고, operator도 하나 또는 그 이상의 operator subtask를 가짐
        *   operator subtask는 서로 독립적이며 다른 스레드 및 다른 시스템이나 컨테이너에서 실행됨
        *   동일한 프로그램의 다른 사용자는 서로 다른 수준의 병렬 처리를 수행할수 있음(job을 등록할때 parallelism값을 조정가능)
        *   Stream은 one-to-one pattern(or forwarding) 또는 redistributing pattern을 통해 데이터를 전송할수 있음
            *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/parallel.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/parallel.html)

    *   Windows
                ![]({{ site.baseurl}}/images/2018-4-25-flink/4E7386E5-A62C-4526-AC27-6331091DF8AF.png)  
        *   [https://flink.apache.org/news/2015/12/04/Introducing-windows.html](https://flink.apache.org/news/2015/12/04/Introducing-windows.html)
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/windows.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/operators/windows.html)
    
    *   Time
                ![]({{ site.baseurl}}/images/2018-4-25-flink/F871C8E7-910E-432C-848B-0DB2E1A78120.png)  
        *   Event time
            *   event가 생성된 시간(watermarks를 구현하여 재정의 가능)
            *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event\_timestamps\_watermarks.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event_timestamps_watermarks.html)

        *   Ingestion time
            *   Flink Source에 진입한 시간

        *   Processing time
            *   시간 기반 operation을 처리하기 위한 시스템 시간(window…)
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event_time.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/event_time.html)
    
    *   Stateful Operations
                    ![]({{ site.baseurl}}/images/2018-4-25-flink/D823BFD5-CE2B-4AD2-B6BC-226F0958910E.png)  
        *   여러 이벤트의 상태 정보를 저장할때 사용
        *   stateful operation의 state는 key/value로 저장됨
        *   state는 stateful operator에 의해 읽혀진 stream과 함께 분할되고 분배됨
        *   key/value state는 keyBy() 함수 이후에 keyed stream에서만 접근 가능하며, 현재 이벤트 키에 관련된 값으로 제한됨
        *   stream key와 state key를 정렬하면 모든 상태 업데이트가 로컬 작업이므로 트랜잭션 오버 헤드없이 일관성을 보장 가능함
        *   정렬은 Flink가 상태를 재분배하고 스트림 분할을 투명하게 조정함
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/index.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/index.html)
            
    *   Checkpoints for Fault Tolerance
        *   Flink는 stream replay와 checkpointing 을 결합하여 fault tolerance를 구현함
        *   checkpoint는 각 입력 stream의 특정 지점과 각 operation에 대한 state와 관련이 있음
        *   streming dataflow는 operator의 상태를 복원하고 checkpoint 지점에서 이벤트를 replay하여 일관성(정확하게 1 회 처리 의미)을 유지하면서 checkpoint에서 다시 시작이 가능함
        *   The checkpoint interval is a means of trading off the overhead of fault tolerance during execution with the recovery time (the number of events that need to be replayed)
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/internals/stream_checkpointing.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/internals/stream_checkpointing.html)
        
    *   Batch on Streaming
        *   Flink는 streaming program의 특별한 경우로 batch program을 실행함
            *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/index.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/index.html)
        *   bounded stream 사용
        *   DataSet은 내부적으로 데이터 스트림으로 처리됨. 이와 같은 개념은 batch program에 적용되며 streaming program에도 적용됨
        *   예외사항
            *   batch program의 fault tolerance는 checkpoint를 사용하지 않음. 복구는 스트림을 완벽하게 replay함으로써 이루어짐. 이는 입력이 제한되어 있기때문에 가능함. checkpoint를 사용하지 않으므로 프로세스 비용이 절감됨
                *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/fault_tolerance.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/fault_tolerance.html)
            *   DataSet API의 stateful operation은 key/value 인덱스가 아닌 단순히 in-memory/out-of-core 데이터 구조를 사용함
            *   DataSet API는 bounded stream에서만 가능한 특수한 synchronized iteration을 가지고 있음
                *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/iterations.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/iterations.html)


*   Distributed Runtime(ing..)
    *   url
        *   [https://ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/runtime.html](https://ci.apache.org/projects/flink/flink-docs-release-1.4/concepts/runtime.html)

    *   Task and Operator Chains
                    ![]({{ site.baseurl}}/images/2018-4-25-flink/EB684A58-7922-4A26-96A4-9296F64D35F9.png)  
        *   ...
    
    *   Job Managers, Task Managers, Clients
                    ![]({{ site.baseurl}}/images/2018-4-25-flink/B5CBCAE4-714D-4948-92CE-62A0302FC722.png)  
        *   ...

    *   Task Slots and Resources
                    ![]({{ site.baseurl}}/images/2018-4-25-flink/CF6F45E1-452D-458A-9B43-B52311BE4CF5.png)  
    
                    ![]({{ site.baseurl}}/images/2018-4-25-flink/EDBF0974-E8A9-4A88-9E10-89193D8BB549.png)  
        *   ...
    
    *   State Backends
                    ![]({{ site.baseurl}}/images/2018-4-25-flink/0C190980-63C4-412A-ABB4-A589109900F1.png)  
        *   ...
    
    *   Savepoints
        *   ...
  

* * *

*   Test
    *   collectd -> kafka -> flink stream(min/max/sum) -> other topic

*   Test Code
    *   [https://github.com/ainory/FlinkTest/blob/master/src/main/java/com/ainory/flink/tests/FlinkStreamTest.java](https://github.com/ainory/FlinkTest/blob/master/src/main/java/com/ainory/flink/tests/FlinkStreamTest.java)
    
```
     /**
      * collectd -> kafka -> flink(stream window & aggregation) -> ohter topic
      *
      * <p>arguments :
      *     --input-topic COLLECTD_DATA --output-topic ainory-flink-stream-1 --bootstrap.servers spanal-app:9092 --zookeeper.connect spanal-app:2181/kafka --group.id ainory-consummer --auto.offset.reset latest
      *
      * @param args
      */
     public void WindowStreamTest(String[] args){
         try{
             final ParameterTool parameterTool = ParameterTool.fromArgs(args);
 
             StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
 //            env.getConfig().disableSysoutLogging();
             env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(4, 10000));
             env.enableCheckpointing(5000);
             env.getConfig().setGlobalJobParameters(parameterTool);
 
             env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
 
             /**
              * source and mapper
              */
             DataStream<Tuple2<String, Double>> input = env.addSource(new FlinkKafkaConsumer010<>(parameterTool.getRequired("input-topic"),
                                                                      new SimpleStringSchema(),
                                                                      parameterTool.getProperties()))
                                                   .assignTimestampsAndWatermarks(new CustomWatermarkExtractor())
                                                   .map(new CollectdMapper2());
 
             /**
              *  min only aggregation sink
              */
             /*
             input.keyBy(0)
                     .window(TumblingEventTimeWindows.of(Time.minutes(1)))
                     .min(1)
                     .map(new MapFunction<Tuple2<String, Double>, String>() {
                             @Override
                             public String map(Tuple2<String, Double> stringDoubleTuple2) throws Exception {
 
                                 StringBuffer result = new StringBuffer();
 
                                 result.append(stringDoubleTuple2.f0).append(" ==> ").append(stringDoubleTuple2.f1.toString());
 
                                 return result.toString();
                             }
                         })
                     .addSink(new FlinkKafkaProducer010<>(parameterTool.getRequired("output-topic"),
                              new SimpleStringSchema(),
                              parameterTool.getProperties()));
             */
 
             /**
              *  min/max/sum aggregation sink
              */
             // min
             SingleOutputStreamOperator<Tuple2<String, Double>> min = input.keyBy(0)
                     .window(TumblingEventTimeWindows.of(Time.minutes(1)))
                     .min(1);
 
             min.map(new MapFunction<Tuple2<String, Double>, String>() {
                 @Override
                 public String map(Tuple2<String, Double> stringDoubleTuple2) throws Exception {
 
                     StringBuffer result = new StringBuffer();
 
                     result.append(stringDoubleTuple2.f0).append("_min").append(" ==> ").append(stringDoubleTuple2.f1.toString());
 
                     return result.toString();
                 }
             }).addSink(new FlinkKafkaProducer010<>(parameterTool.getRequired("output-topic"),
                     new SimpleStringSchema(),
                     parameterTool.getProperties()));
 
             // max
             SingleOutputStreamOperator<Tuple2<String, Double>> max = input.keyBy(0)
                     .window(TumblingEventTimeWindows.of(Time.minutes(1)))
                     .max(1);
 
             max.map(new MapFunction<Tuple2<String, Double>, String>() {
                 @Override
                 public String map(Tuple2<String, Double> stringDoubleTuple2) throws Exception {
 
                     StringBuffer result = new StringBuffer();
 
                     result.append(stringDoubleTuple2.f0).append("_max").append(" ==> ").append(stringDoubleTuple2.f1.toString());
 
                     return result.toString();
                 }
             }).addSink(new FlinkKafkaProducer010<>(parameterTool.getRequired("output-topic"),
                     new SimpleStringSchema(),
                     parameterTool.getProperties()));
 
             // sum
             SingleOutputStreamOperator<Tuple2<String, Double>> sum = input.keyBy(0)
                     .window(TumblingEventTimeWindows.of(Time.minutes(1)))
                     .sum(1);
 
             sum.map(new MapFunction<Tuple2<String, Double>, String>() {
                 @Override
                 public String map(Tuple2<String, Double> stringDoubleTuple2) throws Exception {
 
                     StringBuffer result = new StringBuffer();
 
                     result.append(stringDoubleTuple2.f0).append("_sum").append(" ==> ").append(stringDoubleTuple2.f1.toString());
 
                     return result.toString();
                 }
             }).addSink(new FlinkKafkaProducer010<>(parameterTool.getRequired("output-topic"),
                     new SimpleStringSchema(),
                     parameterTool.getProperties()));
 
             env.execute("WindowStreamTest for ainory");
 
         }catch (Exception e){
             e.printStackTrace();
         }
     }
```
